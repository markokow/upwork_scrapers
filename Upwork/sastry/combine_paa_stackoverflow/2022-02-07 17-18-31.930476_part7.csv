url,title,best_answer_1,best_answer_2,best_answer_3,keyword,question_1,answer_1,question_2,answer_2,question_3,answer_3,question_4,answer_4
https://stackoverflow.com/questions/2315705/what-is-the-difference-between-i-i-in-a-for-loop,java - What is the difference between i++ & ++i in a for loop?,"<p>They both increment the number. <code>++i</code> is equivalent to <code>i = i + 1</code>.</p>
<p><code>i++</code> and <code>++i</code> are very similar but not exactly the same. Both increment the number, but <code>++i</code> increments the number before the current expression is evaluted, whereas <code>i++</code> increments the number after the expression is evaluated.</p>
<pre><code>int i = 3;
int a = i++; // a = 3, i = 4
int b = ++a; // b = 4, a = 4
</code></pre>","<p>Heres a sample class: </p>
<pre><code>public class Increment
{
    public static void main(String [] args)
    {
        for (int i = 0; i &lt; args.length; ++i)
        {
            System.out.println(args[i]);
        }
    }
}
</code></pre>
<p>If I disassemble this class using javap.exe I get this: </p>
<pre><code>Compiled from Increment.java
public class Increment extends java.lang.Object{
public Increment();
  Code:
   0:   aload_0
   1:   invokespecial   #1; //Method java/lang/Object.&lt;init&gt;:()V
   4:   return

public static void main(java.lang.String[]);
  Code:
   0:   iconst_0
   1:   istore_1
   2:   iload_1
   3:   aload_0
   4:   arraylength
   5:   if_icmpge       23
   8:   getstatic       #2; //Field java/lang/System.out:Ljava/io/PrintStream;
   11:  aload_0
   12:  iload_1
   13:  aaload
   14:  invokevirtual   #3; //Method java/io/PrintStream.println:(Ljava/lang/String;)V
   17:  iinc    1, 1
   20:  goto    2
   23:  return

}
</code></pre>
<p>If I change the loop so it uses i++ and disassemble again I get this: </p>
<pre><code>Compiled from Increment.java
public class Increment extends java.lang.Object{
public Increment();
  Code:
   0:   aload_0
   1:   invokespecial   #1; //Method java/lang/Object.&lt;init&gt;:()V
   4:   return

public static void main(java.lang.String[]);
  Code:
   0:   iconst_0
   1:   istore_1
   2:   iload_1
   3:   aload_0
   4:   arraylength
   5:   if_icmpge       23
   8:   getstatic       #2; //Field java/lang/System.out:Ljava/io/PrintStream;
   11:  aload_0
   12:  iload_1
   13:  aaload
   14:  invokevirtual   #3; //Method java/io/PrintStream.println:(Ljava/lang/String;)V
   17:  iinc    1, 1
   20:  goto    2
   23:  return

}
</code></pre>
<p>When I compare the two, TextPad tells me that the two are identical. </p>
<p>What this says is that from the point of view of the generated byte code theres no difference in a loop.  In other contexts there is a difference between ++i and i++, but not for loops.</p>","<p>Both of them increase the variable <code>i</code> by one. Its like saying <code>i = i + 1</code>. The difference is subtle. If youre using it in a loop like this, theres no difference:</p>
<pre><code>for (int i = 0; i &lt; 100; i++) {
}

for (int i = 0; i &lt; 100; ++i) {
}
</code></pre>
<p>If you want to know the difference, look at this example:</p>
<pre><code>int a = 0;
int b = a++; // b = 0; a = 1

a = 0;
b = ++a: // b = 1; a = 1
</code></pre>
<p>The idea is that <code>++a</code> increments <code>a</code> and returns that value, while <code>a++</code> returns as value and then increments <code>a</code>.</p>",i++ vs ++i java,i++ vs ++i java,"Increment in java is performed in two ways, 1) Post-Increment (i++): we use i++ in our statement if we want to use the current value, and then we want to increment the value of i by 1. 2) Pre-Increment(++i): We use ++i in our statement if we want to increment the value of i by 1 and then use it in our statement.",What is the difference between ++ i and i ++ java?,"If ++ precedes the variable, it is called pre-increment operator and it comes after a variable, it is called post-increment operator. Increment in java is performed in two ways, 1) Post-Increment (i++): we use i++ in our statement if we want to use the current value, and then we want to increment the value of i by 1.",Is there a difference between ++ i and i ++ in a for loop?,"Both increment the number, but ++i increments the number before the current expression is evaluted, whereas i++ increments the number after the expression is evaluated. To answer the actual question, however, they're essentially identical within the context of typical for loop usage.",What is the difference between I -- and -- I in java?,--i decrements i by 1 then gives you the value of i (4). i-- gives you the value of i (5) then decrements it by 1. Both will give you the same result in a for loop.
https://stackoverflow.com/questions/34240703/what-are-logits-what-is-the-difference-between-softmax-and-softmax-cross-entrop,python - What are logits? What is the difference between softmax and softmax_cross_entropy_with_logits?,"<p>The softmax+logits simply means that the function operates on the unscaled output of earlier layers and that the relative scale to understand the units is linear.  It means, in particular, the sum of the inputs may not equal 1, that the values are <em>not</em> probabilities (you might have an input of 5). Internally, it first applies softmax to the unscaled output, and then and then computes the cross entropy of those values vs. what they should be as defined by the labels.</p>
<p><code>tf.nn.softmax</code> produces the result of applying the <a href=https://en.wikipedia.org/wiki/Softmax_function rel=noreferrer>softmax function</a> to an input tensor.  The softmax squishes the inputs so that <code>sum(input) = 1</code>, and it does the mapping by interpreting the inputs as log-probabilities (logits) and then converting them back into raw probabilities between 0 and 1.  The shape of output of a softmax is the same as the input:</p>
<pre><code>a = tf.constant(np.array([[.1, .3, .5, .9]]))
print s.run(tf.nn.softmax(a))
[[ 0.16838508  0.205666    0.25120102  0.37474789]]
</code></pre>
<p>See <a href=https://stackoverflow.com/questions/17187507/why-use-softmax-as-opposed-to-standard-normalization>this answer</a> for more about why softmax is used extensively in DNNs.</p>
<p><code>tf.nn.softmax_cross_entropy_with_logits</code> combines the softmax step with the calculation of the cross-entropy loss after applying the softmax function, but it does it all together in a more mathematically careful way.  Its similar to the result of:</p>
<pre><code>sm = tf.nn.softmax(x)
ce = cross_entropy(sm)
</code></pre>
<p>The cross entropy is a summary metric: it sums across the elements.  The output of <code>tf.nn.softmax_cross_entropy_with_logits</code> on a shape <code>[2,5]</code> tensor is of shape <code>[2,1]</code> (the first dimension is treated as the batch).</p>
<p>If you want to do optimization to minimize the cross entropy <strong>AND</strong> youre softmaxing after your last layer, you should use <code>tf.nn.softmax_cross_entropy_with_logits</code> instead of doing it yourself, because it covers numerically unstable corner cases in the mathematically right way.  Otherwise, youll end up hacking it by adding little epsilons here and there.</p>
<p><strong>Edited 2016-02-07:</strong>
If you have single-class labels, where an object can only belong to one class, you might now  consider using <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code> so that you dont have to convert your labels to a dense one-hot array.  This function was added after release 0.6.0.</p>","<p><strong>Short version:</strong></p>
<p>Suppose you have two tensors, where <code>y_hat</code> contains computed scores for each class (for example, from y = W*x +b) and <code>y_true</code> contains one-hot encoded true labels. </p>
<pre><code>y_hat  = ... # Predicted label, e.g. y = tf.matmul(X, W) + b
y_true = ... # True label, one-hot encoded
</code></pre>
<p>If you interpret the scores in <code>y_hat</code> as unnormalized log probabilities, then they are <strong>logits</strong>.</p>
<p>Additionally, the total cross-entropy loss computed in this manner:</p>
<pre><code>y_hat_softmax = tf.nn.softmax(y_hat)
total_loss = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(y_hat_softmax), [1]))
</code></pre>
<p>is essentially equivalent to the total cross-entropy loss computed with the function <code>softmax_cross_entropy_with_logits()</code>:</p>
<pre><code>total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_hat, y_true))
</code></pre>
<p><strong>Long version:</strong></p>
<p>In the output layer of your neural network, you will probably compute an array that contains the class scores for each of your training instances, such as from a computation <code>y_hat = W*x + b</code>. To serve as an example, below Ive created a <code>y_hat</code> as a 2 x 3 array, where the rows correspond to the training instances and the columns correspond to classes. So here there are 2 training instances and 3 classes.</p>
<pre><code>import tensorflow as tf
import numpy as np

sess = tf.Session()

# Create example y_hat.
y_hat = tf.convert_to_tensor(np.array([[0.5, 1.5, 0.1],[2.2, 1.3, 1.7]]))
sess.run(y_hat)
# array([[ 0.5,  1.5,  0.1],
#        [ 2.2,  1.3,  1.7]])
</code></pre>
<p>Note that the values are not normalized (i.e. the rows dont add up to 1). In order to normalize them, we can apply the softmax function, which interprets the input as unnormalized log probabilities (aka <strong>logits</strong>) and outputs normalized linear probabilities. </p>
<pre><code>y_hat_softmax = tf.nn.softmax(y_hat)
sess.run(y_hat_softmax)
# array([[ 0.227863  ,  0.61939586,  0.15274114],
#        [ 0.49674623,  0.20196195,  0.30129182]])
</code></pre>
<p>Its important to fully understand what the softmax output is saying. Below Ive shown a table that more clearly represents the output above. It can be seen that, for example, the probability of training instance 1 being Class 2 is 0.619. The class probabilities for each training instance are normalized, so the sum of each row is 1.0.</p>
<pre><code>                      Pr(Class 1)  Pr(Class 2)  Pr(Class 3)
                    ,--------------------------------------
Training instance 1 | 0.227863   | 0.61939586 | 0.15274114
Training instance 2 | 0.49674623 | 0.20196195 | 0.30129182
</code></pre>
<p>So now we have class probabilities for each training instance, where we can take the argmax() of each row to generate a final classification. From above, we may generate that training instance 1 belongs to Class 2 and training instance 2 belongs to Class 1. </p>
<p>Are these classifications correct? We need to measure against the true labels from the training set. You will need a one-hot encoded <code>y_true</code> array, where again the rows are training instances and columns are classes. Below Ive created an example <code>y_true</code> one-hot array where the true label for training instance 1 is Class 2 and the true label for training instance 2 is Class 3.</p>
<pre><code>y_true = tf.convert_to_tensor(np.array([[0.0, 1.0, 0.0],[0.0, 0.0, 1.0]]))
sess.run(y_true)
# array([[ 0.,  1.,  0.],
#        [ 0.,  0.,  1.]])
</code></pre>
<p>Is the probability distribution in <code>y_hat_softmax</code> close to the probability distribution in <code>y_true</code>? We can use <a href=https://en.wikipedia.org/wiki/Cross_entropy>cross-entropy loss</a> to measure the error.</p>
<p><a href=https://i.stack.imgur.com/rODko.png><img alt=Formula for cross-entropy loss src=https://i.stack.imgur.com/rODko.png/></a></p>
<p>We can compute the cross-entropy loss on a row-wise basis and see the results. Below we can see that training instance 1 has a loss of 0.479, while training instance 2 has a higher loss of 1.200. This result makes sense because in our example above, <code>y_hat_softmax</code> showed that training instance 1s highest probability was for Class 2, which matches training instance 1 in <code>y_true</code>; however, the prediction for training instance 2 showed a highest probability for Class 1, which does not match the true class Class 3.</p>
<pre><code>loss_per_instance_1 = -tf.reduce_sum(y_true * tf.log(y_hat_softmax), reduction_indices=[1])
sess.run(loss_per_instance_1)
# array([ 0.4790107 ,  1.19967598])
</code></pre>
<p>What we really want is the total loss over all the training instances. So we can compute:</p>
<pre><code>total_loss_1 = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(y_hat_softmax), reduction_indices=[1]))
sess.run(total_loss_1)
# 0.83934333897877944
</code></pre>
<p><strong>Using softmax_cross_entropy_with_logits()</strong></p>
<p>We can instead compute the total cross entropy loss using the <code>tf.nn.softmax_cross_entropy_with_logits()</code> function, as shown below. </p>
<pre><code>loss_per_instance_2 = tf.nn.softmax_cross_entropy_with_logits(y_hat, y_true)
sess.run(loss_per_instance_2)
# array([ 0.4790107 ,  1.19967598])

total_loss_2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_hat, y_true))
sess.run(total_loss_2)
# 0.83934333897877922
</code></pre>
<p>Note that <code>total_loss_1</code> and <code>total_loss_2</code> produce essentially equivalent results with some small differences in the very final digits. However, you might as well use the second approach: it takes one less line of code and accumulates less numerical error because the softmax is done for you inside of <code>softmax_cross_entropy_with_logits()</code>.</p>","<p><code>tf.nn.softmax</code> computes the forward propagation through a softmax layer. You use it during <strong>evaluation</strong> of the model when you compute the probabilities that the model outputs.</p>
<p><code>tf.nn.softmax_cross_entropy_with_logits</code> computes the cost for a softmax layer. It is only used during <strong>training</strong>. </p>
<p>The logits are the <em>unnormalized log probabilities</em> output the model (the values output before the softmax normalization is applied to them).</p>",tf.nn.softmax_cross_entropy_with_logits,What is TF nn Softmax_cross_entropy_with_logits?,"nn. softmax_cross_entropy_with_logits( labels, logits, axis=- name=None. ) Measures the probability error in discrete classification tasks in which the classes are mutually exclusive (each entry is in exactly one class).",What is Softmax_cross_entropy_with_logits?,"tf.nn.softmax_cross_entropy_with_logits combines the softmax step with the calculation of the cross-entropy loss after applying the softmax function, but it does it all together in a more mathematically careful way. It's similar to the result of: sm = tf.nn.softmax(x) ce = cross_entropy(sm)",What does logits mean in TensorFlow?,"The vector of raw (non-normalized) predictions that a classification model generates, which is ordinarily then passed to a normalization function. If the model is solving a multi-class classification problem, logits typically become an input to the softmax function.",What does From_logits mean?,"The from_logits=True attribute inform the loss function that the output values generated by the model are not normalized, a.k.a. logits. In other words, the softmax function has not been applied on them to produce a probability distribution."
https://stackoverflow.com/questions/41342609/the-difference-between-comparison-to-np-nan-and-isnull,python - The difference between comparison to np.nan and isnull(),"<p><code>np.nan</code> is not comparable to <code>np.nan</code>... directly.</p>
<pre><code>np.nan == np.nan

False
</code></pre>
<p>While</p>
<pre><code>np.isnan(np.nan)

True
</code></pre>
<p>Could also do</p>
<pre><code>pd.isnull(np.nan)

True
</code></pre>
<hr/>
<p><strong><em>examples</em></strong><br/>
Filters nothing because nothing is equal to <code>np.nan</code></p>
<pre><code>s = pd.Series([1., np.nan, 2.])
s[s != np.nan]

0    1.0
1    NaN
2    2.0
dtype: float64
</code></pre>
<p>Filters out the null</p>
<pre><code>s = pd.Series([1., np.nan, 2.])
s[s.notnull()]

0    1.0
2    2.0
dtype: float64
</code></pre>
<p>Use odd comparison behavior to get what we want anyway.  If <code>np.nan != np.nan</code> is <code>True</code> then  </p>
<pre><code>s = pd.Series([1., np.nan, 2.])
s[s == s]

0    1.0
2    2.0
dtype: float64
</code></pre>
<p>Just <code>dropna</code> </p>
<pre><code>s = pd.Series([1., np.nan, 2.])
s.dropna()

0    1.0
2    2.0
dtype: float64
</code></pre>",,,np nan,What does NP NaN mean?,nanmean() function can be used to calculate the mean of array ignoring the NaN value. If array have NaN value and we can find out the mean without effect of NaN value.,How do you use NP NaN?,To check for NaN values in a Numpy array you can use the np. isnan() method. This outputs a boolean mask of the size that of the original array. The output array has true for the indices which are NaNs in the original array and false for the rest.,What type is NP NaN?,"The np. nan is the IEEE 754 floating-point representation of Not a Number. The nan stands for “not a number“, and its primary constant is to act as a placeholder for any missing numerical values in the array. The nan values are constants defined in numpy: nan, inf.The np. nan is the IEEE 754 floating-pointfloating-pointIn computing, floating point operations per second (FLOPS, flops or flop/s) is a measure of computer performance, useful in fields of scientific computations that require floating-point calculations. For such cases, it is a more accurate measure than measuring instructions per second.https://en.wikipedia.org › wiki › FLOPSFLOPS - Wikipedia representation of Not a Number. The nan stands for “not a number“, and its primary constant is to act as a placeholder for any missing numerical values in the array. The nan values are constants defined in numpy: nan, inf.

floating-pointIn computing, floating point operations per second (FLOPS, flops or flop/s) is a measure of computer performance, useful in fields of scientific computations that require floating-point calculations. For such cases, it is a more accurate measure than measuring instructions per second.https://en.wikipedia.org › wiki › FLOPSFLOPS - Wikipedia
› wiki › FLOPS
floating-pointfloating-pointIn computing, floating point operations per second (FLOPS, flops or flop/s) is a measure of computer performance, useful in fields of scientific computations that require floating-point calculations. For such cases, it is a more accurate measure than measuring instructions per second.https://en.wikipedia.org › wiki › FLOPSFLOPS - Wikipedia
floating-point
The np. nan is the IEEE 754 floating-pointfloating-pointIn computing, floating point operations per second (FLOPS, flops or flop/s) is a measure of computer performance, useful in fields of scientific computations that require floating-point calculations. For such cases, it is a more accurate measure than measuring instructions per second.https://en.wikipedia.org › wiki › FLOPSFLOPS - Wikipedia representation of Not a Number. The nan stands for “not a number“, and its primary constant is to act as a placeholder for any missing numerical values in the array. The nan values are constants defined in numpy: nan, inf.",What does NP NaN stand for?,nanmean() function can be used to calculate the mean of array ignoring the NaN value. If array have NaN value and we can find out the mean without effect of NaN value.
https://stackoverflow.com/questions/43495864/can-anyone-explain-the-use-of-q-service-in-angularjs,Can anyone explain the use of $q service in angularjs?,"<p>I think the article I wrote about $q might help you. </p>
<p><strong>Introduction to $q</strong></p>
<p>$q is an angular defined service. It’s the same as new Promise(). But $q takes things to the next level by enhancing additional feature that developers can use to perform complex tasks more simply.</p>
<p>This is a sample for creating a promise using $q</p>
<pre><code>angular.module(app,[])
.controller(ctrl,function($scope,$q){
  var work = resolve;
  var promise = $q(function(resolve, reject) {
    if (work === resolve) {
        resolve(response 1!);
    } else {
        reject(Oops... something went wrong);
    }
  }); 
  promise.then(function(data) {
    alert(data)  

  }) 
})
</code></pre>
<p><strong>$q.defer()</strong></p>
<p>$q.defer() return the instance of the promise constructor. Once you create a defer object there are following methods and properties that you can access from that object</p>
<p><code>resolve(value)</code> – resolves the derived promise with the value. If the value is a rejection constructed via $q.reject, the promise will be rejected instead.</p>
<p><code>reject(reason)</code> – rejects the derived promise with the reason. This is equivalent to resolving it with a rejection constructed via $q.reject.</p>
<p><code>notify(value)</code> - provides updates on the status of the promises execution. This may be called multiple times before the promise is either resolved or rejected.</p>
<p><code>promise</code> – {Promise} – promise object associated with this deferred</p>
<p>See the example</p>
<pre><code>angular.module(app,[])
.controller(ctrl,function($scope,$q){
  var work = resolve;

  function getData(){
    var obj = $q.defer();

    if (work === resolve) {
        obj.resolve(response 1!);
    } else {
        obj.reject(Oops... something went wrong);
    }

    return obj.promise;
  } 
  getData().then(function(data) {
    alert(data)  

  }) 
})    
</code></pre>
<p><strong>$q.all()</strong></p>
<p>If a user need to send multiple request one shot,then the user can use $q.all() service.</p>
<pre><code> $q.all([$http.get(data1.json),$http.get(data2.json)])
      .then(function(response){
        console.log(response[0].data) // data1.json response 
        console.log(response[1].data) // data1.json response 
 })
</code></pre>
<p>In here,there are two http request sent simultaneously to two separate JSON files to get data. The response comes as an array and response order is same as the HTTP request order. </p>
<p><strong>$q.race()</strong></p>
<p>$q.race() is very similar to $q.all(). But instead of sending response of each request, it will only return the one request response. Specifically, only return the response of first request that been executed. That does not mean it’s not going to send other requests. All the requests are sending but its only return the response of the first request that executed.</p>
<pre><code> $q.race([$http.get(data1.json),$http.get(data2.json)])
      .then(function(response){
        console.log(response[0].data) // return one response 
 })
</code></pre>
<p>In here response can be either data1.Json or data2.json. Thats the downfall of using this method. Since its return the response of the first executed request, can’t be sure which request response will resolved by the promise. This method useful for bulk requests which you don’t want to see the response of all the requests</p>
<p><strong>Conclusion</strong></p>
<p>Use $q for constructing promises from non-promise Objects/callbacks, and utilize $q.all() and $q.race() to work with existing promises.</p>","<p>I like this question. Because, I too faced this.</p>
<p>This is a service that helps you run functions asynchronously, and use their return values when they are done processing.</p>
<p><a href=https://docs.angularjs.org/api/ng/service/$q rel=noreferrer>Brief Description</a></p>
<p><a href=http://jsfiddle.net/Zenuka/pHEf9/21/ rel=noreferrer>Refer example</a></p>
<p><a href=http://www.webdeveasy.com/javascript-promises-and-angularjs-q-service/ rel=noreferrer>Promise with $q</a></p>
<p>Example :</p>
<pre><code>app.service(githubService, function($http, $q) {

    var deferred = $q.defer();

    this.getAccount = function() {
        return $http.get(https://api.github.com/users/haroldrv)
            .then(function(response) {
                // promise is fulfilled
                deferred.resolve(response.data);
                // promise is returned
                return deferred.promise;
            }, function(response) {
                // the following line rejects the promise 
                deferred.reject(response);
                // promise is returned
                return deferred.promise;
            });
    };
});
</code></pre>",,angularjs $q,What is Q in angular?,"$q is integrated with the $rootScope. Scope Scope model observation mechanism in AngularJS, which means faster propagation of resolution or rejection into your models and avoiding unnecessary browser repaints, which would result in flickering UI. Q has many more features than $q, but that comes at a cost of bytes.",What is Q All in AngularJS?,"$q is an Angular Service which facilitates running functions asynchronously. It's based on a library (Q) by Kris Kowal. $q. all() allows us to wait on an array (or object) of promises, $q. all() will combine these into a single promise.",Why is Q service used?,"A service that helps you run functions asynchronously, and use their return values (or exceptions) when they are done processing.",What is Q all?,"$q is an Angular Service which facilitates running functions asynchronously. It's based on a library (Q) by Kris Kowal. $q. all() allows us to wait on an array (or object) of promises, $q. all() will combine these into a single promise."
https://stackoverflow.com/questions/24003431/python-typeerror-numpy-float64-object-cannot-be-interpreted-as-an-integer/24003477,loops - python TypeError: numpy.float64 object cannot be interpreted as an integer,"<pre><code>N=np.floor(np.divide(l,delta))
...
for j in range(N[i]/2):
</code></pre>
<p><code>N[i]/2</code> will be a <code>float64</code> but <code>range()</code> expects an integer. Just cast the call to</p>
<pre><code>for j in range(int(N[i]/2)):
</code></pre>","<p>I came here with the same Error, though one with a different origin.</p>
<blockquote>
<p>It is caused by unsupported float index in 1.12.0 and newer numpy versions
  even if the code should be considered as valid.</p>
</blockquote>
<p>An <code>int</code> type is expected, not a <code>np.float64</code></p>
<p>Solution: Try to install <code>numpy 1.11.0</code> </p>
<pre><code>sudo pip install -U numpy==1.11.0.
</code></pre>","<p>I had the same problems when I was training a retained object detection model (faster RCNN) and this worked for me perfectly:</p>
<pre><code>pip uninstall pycocotools
pip install pycocotools-windows
</code></pre>",'numpy.float64' object cannot be interpreted as an integer,'numpy.float64' object cannot be interpreted as an integer,This error occurs when you supply a float to some function that expects an integer.,,,,,,
https://stackoverflow.com/questions/15706270/sort-a-table-in-lua,sorting - Sort a Table[] in Lua,"<p>A table in Lua is a set of key-value mappings with unique keys. The pairs are stored in arbitrary order and therefore the table is not sorted in any way.</p>
<p>What you can do is <em>iterate</em> over the table in some order. The basic <code>pairs</code> gives you no guarantee of the order in which the keys are visited. Here is a customized version of <code>pairs</code>, which I called <code>spairs</code> because it iterates over the table in a sorted order:</p>
<pre><code>function spairs(t, order)
    -- collect the keys
    local keys = {}
    for k in pairs(t) do keys[#keys+1] = k end

    -- if order function given, sort by it by passing the table and keys a, b,
    -- otherwise just sort the keys 
    if order then
        table.sort(keys, function(a,b) return order(t, a, b) end)
    else
        table.sort(keys)
    end

    -- return the iterator function
    local i = 0
    return function()
        i = i + 1
        if keys[i] then
            return keys[i], t[keys[i]]
        end
    end
end
</code></pre>
<p>Here is an example of use of such function:</p>
<pre><code>HighScore = { Robin = 8, Jon = 10, Max = 11 }

-- basic usage, just sort by the keys
for k,v in spairs(HighScore) do
    print(k,v)
end
--&gt; Jon     10
--&gt; Max     11
--&gt; Robin   8

-- this uses an custom sorting function ordering by score descending
for k,v in spairs(HighScore, function(t,a,b) return t[b] &lt; t[a] end) do
    print(k,v)
end
--&gt; Max     11
--&gt; Jon     10
--&gt; Robin   8
</code></pre>","<p>An alternative way of sorting that avoids iterators and such is to pass the table to a list of key-value pairs (i.e.: list = {{k1,v1}, {k2, v2}, ...}.  Heres my solution:</p>
<pre><code>local ranks = {}
for player,kills in pairs(tableOfKills) do
    table.insert(ranks, {player, kills})
end

-- Now we use Luas built-in sort function with a short custom comparator function:
table.sort(ranks, function (a, b) return a[2] &gt; b[2] end)

-- The only thing left to do is display the results:
for i=1,#ranks do
    print(ranks[i][1], ranks[i][2])
end
</code></pre>",,lua table sort,What does table sort do Lua?,One of the most used functions in Lua is the sort function which is provided by the Lua library which tables a table as an argument and sorts the values that are present inside the table. The sort function also takes one more argument with the table and that argument is a function which is known as the order function.,Is Lua table sort stable?,"""[Table. sort] algorithm is not stable; that is, elements considered equal by the given order may have their relative positions changed by the sort.""",How do you use table sort?,"Select a cell within the data.
Select Home > Sort & Filter. Or, select Data > Sort.
Select an option: Sort A to Z - sorts the selected column in an ascending order. Sort Z to A - sorts the selected column in a descending order.",How do you use next in Lua?,"When the next() function is called with nil value as the second argument, next returns an initial index and the associated value.
When the next() function is called with the last index of the table or with nil in the empty table, Lua next will return nil."
https://stackoverflow.com/questions/35919020/whats-the-difference-of-name-scope-and-a-variable-scope-in-tensorflow,Whats the difference of name scope and a variable scope in tensorflow?,"<p>Lets begin by a short introduction to variable sharing. It is a mechanism in <code>TensorFlow</code> that allows for sharing variables accessed in different parts of the code without passing references to the variable around. </p>
<p>The method <a href=https://www.tensorflow.org/api_docs/python/tf/get_variable rel=noreferrer><code>tf.get_variable</code></a> can be used with the name of the variable as the argument to either create a new variable with such name or retrieve the one that was created before. This is different from using the <a href=https://www.tensorflow.org/api_docs/python/tf/Variable rel=noreferrer><code>tf.Variable</code></a> constructor which will create a new variable every time it is called (and potentially add a suffix to the variable name if a variable with such name already exists). </p>
<p>It is for the purpose of the variable sharing mechanism that a separate type of scope (variable scope) was introduced.</p>
<p>As a result, we end up having two different types of scopes:</p>
<ul>
<li><em>name scope</em>, created using <a href=https://www.tensorflow.org/api_docs/python/tf/name_scope rel=noreferrer><code>tf.name_scope</code></a></li>
<li><em>variable scope</em>, created using <a href=https://www.tensorflow.org/api_docs/python/tf/variable_scope rel=noreferrer><code>tf.variable_scope</code></a></li>
</ul>
<p>Both scopes have the same effect on all operations as well as variables created using <code>tf.Variable</code>, i.e., the scope will be added as a prefix to the operation or variable name. </p>
<p>However, name scope is ignored by <code>tf.get_variable</code>. We can see that in the following example:</p>
<pre class=lang-python prettyprint-override><code>with tf.name_scope(my_scope):
    v1 = tf.get_variable(var1, [1], dtype=tf.float32)
    v2 = tf.Variable(1, name=var2, dtype=tf.float32)
    a = tf.add(v1, v2)

print(v1.name)  # var1:0
print(v2.name)  # my_scope/var2:0
print(a.name)   # my_scope/Add:0
</code></pre>
<p>The only way to place a variable accessed using <code>tf.get_variable</code> in a scope is to use a variable scope, as in the following example:</p>
<pre class=lang-python prettyprint-override><code>with tf.variable_scope(my_scope):
    v1 = tf.get_variable(var1, [1], dtype=tf.float32)
    v2 = tf.Variable(1, name=var2, dtype=tf.float32)
    a = tf.add(v1, v2)

print(v1.name)  # my_scope/var1:0
print(v2.name)  # my_scope/var2:0
print(a.name)   # my_scope/Add:0
</code></pre>
<p>This allows us to easily share variables across different parts of the program, even within different name scopes:</p>
<pre class=lang-python prettyprint-override><code>with tf.name_scope(foo):
    with tf.variable_scope(var_scope):
        v = tf.get_variable(var, [1])
with tf.name_scope(bar):
    with tf.variable_scope(var_scope, reuse=True):
        v1 = tf.get_variable(var, [1])
assert v1 == v
print(v.name)   # var_scope/var:0
print(v1.name)  # var_scope/var:0
</code></pre>
<hr/>
<h2>UPDATE</h2>
<p><strong>As of version r0.11, <code>op_scope</code> and <code>variable_op_scope</code> are both <a href=https://www.tensorflow.org/versions/r0.11/api_docs/python/state_ops/sharing_variables#variable_op_scope rel=noreferrer>deprecated</a> and replaced by <code>name_scope</code> and <code>variable_scope</code>.</strong> </p>","<p>Both <a href=https://www.tensorflow.org/api_docs/python/tf/variable_op_scope rel=noreferrer>variable_op_scope</a> and <a href=https://www.tensorflow.org/api_docs/python/tf/op_scope rel=noreferrer>op_scope</a> are now deprecated and should not be used at all. </p>
<p>Regarding the other two, I also had problems understanding the difference between <a href=https://www.tensorflow.org/api_docs/python/tf/variable_scope rel=noreferrer>variable_scope</a> and <a href=https://www.tensorflow.org/api_docs/python/tf/name_scope rel=noreferrer>name_scope</a> (they looked almost the same) before I tried to visualize everything by creating a simple example:</p>
<pre class=lang-python prettyprint-override><code>import tensorflow as tf


def scoping(fn, scope1, scope2, vals):
    with fn(scope1):
        a = tf.Variable(vals[0], name=a)
        b = tf.get_variable(b, initializer=vals[1])
        c = tf.constant(vals[2], name=c)

        with fn(scope2):
            d = tf.add(a * b, c, name=res)

        print \n  .join([scope1, a.name, b.name, c.name, d.name]), \n
    return d

d1 = scoping(tf.variable_scope, scope_vars, res, [1, 2, 3])
d2 = scoping(tf.name_scope,     scope_name, res, [1, 2, 3])

with tf.Session() as sess:
    writer = tf.summary.FileWriter(logs, sess.graph)
    sess.run(tf.global_variables_initializer())
    print sess.run([d1, d2])
    writer.close()
</code></pre>
<p>Here I create a function that creates some variables and constants and groups them in scopes (depending on the type I provided). In this function, I also print the names of all the variables. After that, I executes the graph to get values of the resulting values and save event-files to investigate them in TensorBoard. If you run this, you will get the following:</p>
<pre><code>scope_vars
  scope_vars/a:0
  scope_vars/b:0
  scope_vars/c:0
  scope_vars/res/res:0 

scope_name
  scope_name/a:0
  b:0
  scope_name/c:0
  scope_name/res/res:0 
</code></pre>
<p>You see the similar pattern if you open TensorBoard (as you see <code>b</code> is outside of <code>scope_name</code> rectangular):</p>
<p><img src=https://i.stack.imgur.com/MN3S3.png width=550/></p>
<hr/>
<p><strong>This gives you the answer</strong>:</p>
<p>Now you see that <code>tf.variable_scope()</code> adds a prefix to the names of all variables (no matter how you create them), ops, constants. On the other hand <code>tf.name_scope()</code> ignores variables created with <code>tf.get_variable()</code> because it assumes that you know which variable and in which scope you wanted to use.</p>
<p>A good documentation on <a href=https://www.tensorflow.org/programmers_guide/variable_scope rel=noreferrer>Sharing variables</a> tells you that </p>
<blockquote>
<p><code>tf.variable_scope()</code>: Manages namespaces for names passed to <code>tf.get_variable()</code>.</p>
</blockquote>
<p>The same documentation provides a more details how does Variable Scope work and when it is useful.</p>","<p>Namespaces is a way to organize names for variables and operators in hierarchical manner (e.g. scopeA/scopeB/scopeC/op1)</p>
<ul>
<li><a href=https://github.com/tensorflow/tensorflow/blob/13ea3ca91ba5aecab6f21acc14b9cb6a9afa8630/tensorflow/python/framework/ops.py#L2395 rel=noreferrer><code>tf.name_scope</code></a> creates namespace for operators in the default graph.</li>
<li><p><a href=https://github.com/tensorflow/tensorflow/blob/13ea3ca91ba5aecab6f21acc14b9cb6a9afa8630/tensorflow/python/ops/variable_scope.py#L403 rel=noreferrer><code>tf.variable_scope</code></a> creates namespace for both variables and operators in the default graph.</p></li>
<li><p><a href=https://github.com/tensorflow/tensorflow/blob/13ea3ca91ba5aecab6f21acc14b9cb6a9afa8630/tensorflow/python/framework/ops.py#L3511 rel=noreferrer><code>tf.op_scope</code></a> same as <code>tf.name_scope</code>, but for the graph in which specified variables were created.</p></li>
<li><p><a href=https://github.com/tensorflow/tensorflow/blob/13ea3ca91ba5aecab6f21acc14b9cb6a9afa8630/tensorflow/python/ops/variable_scope.py#L501 rel=noreferrer><code>tf.variable_op_scope</code></a> same as <code>tf.variable_scope</code>, but for the graph in which specified variables were created.</p></li>
</ul>
<p>Links to the sources above help to disambiguate this documentation issue.</p>
<p><a href=https://gist.github.com/alexgorban/fa5755c7f7fa49b47961 rel=noreferrer>This example</a> shows that all types of scopes define namespaces for both variables and operators with following differences:</p>
<ol>
<li>scopes defined by <code>tf.variable_op_scope</code> or <code>tf.variable_scope</code> are compatible with <code>tf.get_variable</code> (it ignores two other scopes)</li>
<li><code>tf.op_scope</code> and <code>tf.variable_op_scope</code> just select a graph from a list of specified variables to create a scope for. Other than than their behavior equal to <code>tf.name_scope</code> and <code>tf.variable_scope</code> accordingly</li>
<li><code>tf.variable_scope</code> and <code>variable_op_scope</code> add specified or default initializer. </li>
</ol>",tf.variable_scope,What is with TF Variable_scope?,"default_namedefault_nameA default, in computer science, refers to the preexisting value of a user-configurable setting that is assigned to a software application, computer program or device. ... Such an assignment makes the choice of that setting or value more likely, this is called the default effect.https://en.wikipedia.org › wiki › Default_(computer_science)Default (computer science) - Wikipedia tf.variable_op_scope(values, name, default_name, initializer=None) Returns a context manager for defining an op that creates variables. This context manager validates that the given values are from the same graph, ensures that that graph is the default graph, and pushes a name scope and a variable scope.tf.variable_op_scope(values, name, default_namedefault_nameA default, in computer science, refers to the preexisting value of a user-configurable setting that is assigned to a software application, computer program or device. ... Such an assignment makes the choice of that setting or value more likely, this is called the default effect.https://en.wikipedia.org › wiki › Default_(computer_science)Default (computer science) - Wikipedia, initializer=None) Returns a context manager for defining an op that creates variables. This context manager validates that the given values are from the same graph, ensures that that graph is the default graph, and pushes a name scope and a variable scope. › wiki › Default_(computer_science) tf.variable_op_scope(values, name, default_namedefault_nameA default, in computer science, refers to the preexisting value of a user-configurable setting that is assigned to a software application, computer program or device. ... Such an assignment makes the choice of that setting or value more likely, this is called the default effect.https://en.wikipedia.org › wiki › Default_(computer_science)Default (computer science) - Wikipedia, initializer=None) Returns a context manager for defining an op that creates variables. This context manager validates that the given values are from the same graph, ensures that that graph is the default graph, and pushes a name scope and a variable scope. default_nameA default, in computer science, refers to the preexisting value of a user-configurable setting that is assigned to a software application, computer program or device. ... Such an assignment makes the choice of that setting or value more likely, this is called the default effect.https://en.wikipedia.org › wiki › Default_(computer_science)Default (computer science) - Wikipedia default_name",What is name scope in TensorFlow?,"Used in the tutorials. Migrating model checkpoints. Displaying text data in TensorBoard. Graph-based Neural Structured Learning in TFX. This context manager pushes a name scope, which will make the name of all operations added within it have a prefix.",What is TF get_variable?,"The function tf. get_variable() returns the existing variable with the same name if it exists, and creates the variable with the specified shape and initializer if it does not exist.",How do you reuse variables in TensorFlow?,"reuse means sharing the same variable between different objects.
If you want to share a variable, the second time you refer to that, you need to explicitly specify “reuse=True” in the variable scope of the variable that you wants to reuse, or.
set the variable scope to “reuse=tf.AUTO_REUSE”"
https://stackoverflow.com/questions/11956710/git-recover-deleted-file-where-no-commit-was-made-after-the-delete,git recover deleted file where no commit was made after the delete,"<p>The output tells you what you need to do. <code>git reset HEAD cc.properties</code> etc. </p>
<p>This will unstage the rm operation. After that, running a <code>git status</code> again will tell you that you need to do a <code>git checkout -- cc.properties</code> to get the file back. </p>
<p>Update:
I have this in my config file</p>
<pre><code>$ git config alias.unstage
reset HEAD
</code></pre>
<p>which I usually use to unstage stuff.</p>","<p>Youve staged the deletion so you need to do:</p>
<pre><code>git checkout HEAD cc.properties store/README store/cc.properties
</code></pre>
<p><code>git checkout .</code> only checks out from the index where the deletion has already been staged.</p>",<p>Just do <code>git checkout path/to/file-I-want-to-bring-back.txt</code></p>,git restore deleted file,How do I restore deleted files?,"Right click on the Recycle Bin icon on desktop.
Select Open from the context menu to view files.
Check the box and select files you want to recover.
Right click on a selected file.
Choose 'Restore' to recover the file to its original location.",Can you recover files after deleting?,Navigate and right-click on the folder that contained the permanently deleted folders or files. Select 'Restore previous versions'. Windows will display a list of previous versions of the files that were created with Windows backup. Double-click the previous version of the file or folder thay you want to recover.,How do I undelete a file in GitHub?,"Note how the GitHub desktop application detects that the file has been deleted: To recover your deleted file, right click on the file in GitHub and select discard changes. The file will now be back in the folder where you originally saved it.",How do I undo a deleted file in git?,"You can restore a deleted file from a Git repository using the git checkout command. If you do not know when a file was last deleted, you can use git rev-list to find the checksum of the commit in which that file was deleted. Then, you can check out that commit."
https://stackoverflow.com/questions/27236275/what-does-valueerror-cannot-reindex-from-a-duplicate-axis-mean,python - What does `ValueError: cannot reindex from a duplicate axis` mean?,"<p>This error usually rises when you join / assign to a column when the index has duplicate values. Since you are assigning to a row, I suspect that there is a duplicate value in <code>affinity_matrix.columns</code>, perhaps not shown in your question.</p>","<p>As others have said, youve probably got duplicate values in your original index. To find them do this:</p>
<p><code>df[df.index.duplicated()]</code></p>","<p>Indices with duplicate values often arise if you create a DataFrame by concatenating other DataFrames. IF you dont care about preserving the values of your index, and you want them to be unique values, when you concatenate the the data, set <code>ignore_index=True</code>.</p>
<p>Alternatively, to overwrite your current index with a new one, instead of using <code>df.reindex()</code>, set:</p>
<pre><code>df.index = new_index
</code></pre>",valueerror: cannot reindex from a duplicate axis,How do you fix Valueerror Cannot reindex from a duplicate axis?,"To make sure a Pandas DataFrame cannot contain duplicate values in the index, one can set a flag. Setting the allows_duplicate_labels flag to False will prevent the assignment of duplicate values.",Is it possible for a DataFrame's index to have duplicate values?,"Indicate duplicate index values. Duplicated values are indicated as True values in the resulting array. Either all duplicates, all except the first, or all except the last occurrence of duplicates can be indicated.",What does Reset_index drop true do?,"If you set drop = True , reset_index will delete the index instead of inserting it back into the columns of the DataFrame. If you set drop = True , the current index will be deleted entirely and the numeric index will replace it.",How do I reindex a DataFrame in pandas?,One can reindex a single column or multiple columns by using reindex() method and by specifying the axis we want to reindex. Default values in the new index that are not present in the dataframe are assigned NaN.
https://stackoverflow.com/questions/35572000/how-can-i-plot-a-confusion-matrix,python - How can I plot a confusion matrix?,"<p><a href=https://i.stack.imgur.com/bYbgo.png rel=noreferrer><img alt=enter image description here src=https://i.stack.imgur.com/bYbgo.png/></a></p>
<p>you can use <code>plt.matshow()</code> instead of <code>plt.imshow()</code> or you can use seaborn modules <code>heatmap</code> (<a href=https://seaborn.pydata.org/generated/seaborn.heatmap.html rel=noreferrer>see documentation</a>) to plot the confusion matrix</p>
<pre><code>import seaborn as sn
import pandas as pd
import matplotlib.pyplot as plt
array = [[33,2,0,0,0,0,0,0,0,1,3], 
        [3,31,0,0,0,0,0,0,0,0,0], 
        [0,4,41,0,0,0,0,0,0,0,1], 
        [0,1,0,30,0,6,0,0,0,0,1], 
        [0,0,0,0,38,10,0,0,0,0,0], 
        [0,0,0,3,1,39,0,0,0,0,4], 
        [0,2,2,0,4,1,31,0,0,0,2],
        [0,1,0,0,0,0,0,36,0,2,0], 
        [0,0,0,0,0,0,1,5,37,5,1], 
        [3,0,0,0,0,0,0,0,0,39,0], 
        [0,0,0,0,0,0,0,0,0,0,38]]
df_cm = pd.DataFrame(array, index = [i for i in ABCDEFGHIJK],
                  columns = [i for i in ABCDEFGHIJK])
plt.figure(figsize = (10,7))
sn.heatmap(df_cm, annot=True)
</code></pre>","<p>@bninopaul s answer is not completely for beginners</p>
<p>here is the code you can copy and run </p>
<pre><code>import seaborn as sn
import pandas as pd
import matplotlib.pyplot as plt

array = [[13,1,1,0,2,0],
         [3,9,6,0,1,0],
         [0,0,16,2,0,0],
         [0,0,0,13,0,0],
         [0,0,0,0,15,0],
         [0,0,1,0,0,15]]

df_cm = pd.DataFrame(array, range(6), range(6))
# plt.figure(figsize=(10,7))
sn.set(font_scale=1.4) # for label size
sn.heatmap(df_cm, annot=True, annot_kws={size: 16}) # font size

plt.show()
</code></pre>
<p><img alt=result src=https://i.stack.imgur.com/2bfcE.png/></p>","<p>IF you want <strong>more data</strong> in you confusion matrix, including <strong>totals column</strong> and <strong>totals line</strong>, and <strong>percents</strong> (%) in each cell, <em>like matlab default</em> (see image below)  </p>
<p><a href=https://i.stack.imgur.com/nK6vY.png rel=noreferrer><img alt=enter image description here src=https://i.stack.imgur.com/nK6vY.png/></a></p>
<p>including the Heatmap and other options...</p>
<p>You should have fun with the module above, shared in the github  ; )</p>
<p><a href=https://github.com/wcipriano/pretty-print-confusion-matrix rel=noreferrer>https://github.com/wcipriano/pretty-print-confusion-matrix</a></p>
<hr/>
<p>This module can do your task easily and produces the output above with a lot of params to customize your CM:
<a href=https://i.stack.imgur.com/NuOUD.png rel=noreferrer><img alt=enter image description here src=https://i.stack.imgur.com/NuOUD.png/></a></p>",plot confusion matrix python,How do you plot a confusion matrix in Seaborn?,"To plot a confusion matrix, we have to create a data frame of the confusion matrix, and then we can use the heatmap() function of Seaborn to plot the confusion matrix in Python. For example, let's create a random confusion matrix and plot it using the heatmap() function.",How do you display a confusion matrix in python?,"You need to create a list of the labels and convert it into an array using the np. asarray() method with shape 2,2 . Then, this array of labels must be passed to the attribute annot . This will plot the confusion matrix with the labels annotation.
Plot Confusion Matrix for Binary Classes With Labels You need to create a list of the labels and convert it into an array using the np. asarray() method with shape 2,2 . Then, this array of labels must be passed to the attribute annot . This will plot the confusion matrix with the labels annotation.",How do you visualize a confusion matrix in R?,"Use the confusionMatrix Function to Create a Confusion Matrix in R.
Use the fourfoldplot Function to Visualize Confusion Matrix in R.
Use the autoplot Function to Visualize Confusion Matrix in R.",How do you graph a confusion matrix?,"You need to create a list of the labels and convert it into an array using the np. asarray() method with shape 2,2 . Then, this array of labels must be passed to the attribute annot . This will plot the confusion matrix with the labels annotation.
Plot Confusion Matrix for Binary Classes With Labels You need to create a list of the labels and convert it into an array using the np. asarray() method with shape 2,2 . Then, this array of labels must be passed to the attribute annot . This will plot the confusion matrix with the labels annotation."
https://stackoverflow.com/questions/6065710/how-does-javas-priorityqueue-differ-from-a-min-heap,priority queue - How does Javas PriorityQueue differ from a min-heap?,"<p>The default PriorityQueue is implemented with Min-Heap, that is the top element is the minimum one in the heap.</p>
<p>In order to implement a max-heap, you can create your own Comparator:</p>
<pre><code>import java.util.Comparator;

public class MyComparator implements Comparator&lt;Integer&gt;
{
    public int compare( Integer x, Integer y )
    {
        return y - x;
    }
}
</code></pre>
<p>So, you can create a min-heap and max-heap in the following way:</p>
<pre><code>PriorityQueue minHeap=new PriorityQueue();
PriorityQueue maxHeap=new PriorityQueue(size, new MyComparator());
</code></pre>","<p>For max-heap you can use:</p>
<pre><code>PriorityQueue&lt;Integer&gt; queue = new PriorityQueue&lt;&gt;(10, Collections.reverseOrder());
</code></pre>","<p>Add() works like an insertWithPriority.</p>
<p>You can define priority for the type that you want using the constructor:</p>
<pre><code>PriorityQueue(int, java.util.Comparator)
</code></pre>
<p>look under <a href=https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/PriorityQueue.html rel=nofollow noreferrer>https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/PriorityQueue.html</a></p>
<p>The order the Comparator gives will represent the priority in the queue.</p>",java min heap,Is there a Min-Heap in Java?,A Min-Heap is a complete binary tree in which the value in each internal node is smaller than or equal to the values in the children of that node. Arr[(2 * i) + 1] returns its left child node. ... Arr[(2 * i) + 2] returns its right child node.,Is priority queue a Min-Heap in Java?,"Answers. The default PriorityQueue is implemented with Min-Heap, that is the top element is the minimum one in the heap. Easier max-heap: Queue<Integer> maxHeap = new PriorityQueue<Integer>(Collections.",Does Java have min heap?,"For an easier implementation of min heap, we use the PriorityQueue class java. util. PriorityQueue provided by Java. ... When you add elements to a priority queue, a min heap is built by default.",Does Java have max heap?,"Max Heap In Java A max heap is also a complete binary tree. In a max heap, the root node is greater than or equal to the child nodes. In general, the value of any internal node in a max heap is greater than or equal to its child nodes. A max heap is also a complete binary tree. In a max heap, the root node is greater than or equal to the child nodes. In general, the value of any internal node in a max heap is greater than or equal to its child nodes."
https://stackoverflow.com/questions/15031338/subscript-out-of-bounds-general-definition-and-solution,r - Subscript out of bounds - general definition and solution?,"<p>This is because you try to access an array out of its boundary. </p>
<p>I will show you how you can debug such errors.</p>
<ol>
<li>I set <code>options(error=recover)</code></li>
<li><p>I run <code>reach_full_in &lt;- reachability(krack_full, in)</code> 
I get :</p>
<pre><code>reach_full_in &lt;- reachability(krack_full, in)
Error in reach_mat[i, alter] = 1 : subscript out of bounds
Enter a frame number, or 0 to exit   
1: reachability(krack_full, in)
</code></pre></li>
<li><p>I enter 1  and I get </p>
<pre><code> Called from: top level 
</code></pre></li>
<li><p>I type <code>ls()</code> to see my current variables</p>
<pre><code>  1] *tmp*           alter           g               
     i               j                     m              
    reach_mat       this_node_reach
</code></pre></li>
</ol>
<p>Now, I will see the dimensions of my variables : </p>
<pre><code>Browse[1]&gt; i
[1] 1
Browse[1]&gt; j
[1] 21
Browse[1]&gt; alter
[1] 22
Browse[1]&gt; dim(reach_mat)
[1] 21 21
</code></pre>
<p>You see that alter is out of bounds. 22 &gt; 21 .  in the line :</p>
<pre><code>  reach_mat[i, alter] = 1
</code></pre>
<p>To avoid such error, personally I do this :</p>
<ul>
<li>Try to use <code>applyxx</code> function. They are safer than <code>for</code></li>
<li>I use <code>seq_along</code> and not <code>1:n</code> (1:0)</li>
<li>Try to think in a vectorized solution if you can to avoid <code>mat[i,j]</code> index access.</li>
</ul>
<p><strong>EDIT vectorize the solution</strong></p>
<p>For example, here I see that you dont use the fact that <code>set.vertex.attribute</code> is vectorized.</p>
<p>You can replace:</p>
<pre><code># Set vertex attributes
for (i in V(krack_full)) {
    for (j in names(attributes)) {
        krack_full &lt;- set.vertex.attribute(krack_full, j, index=i, attributes[i+1,j])
    }
}
</code></pre>
<p>by this:</p>
<pre><code>##  set.vertex.attribute is vectorized!
##  no need to loop over vertex!
for (attr in names(attributes))
      krack_full &lt;&lt;- set.vertex.attribute(krack_full, 
                                             attr, value = attributes[,attr])
</code></pre>","<p>Only an addition to the above responses: A possibility in such cases is that you are calling an object, that for some reason is not available to your query. For example you may subset by row names or column names, and you will receive this error message when your requested row or column is not part of the data matrix or data frame anymore. 
Solution: As a short version of the responses above: you need to find the last working row name or column name, and the next called object should be the one that could not be found. 
If you run parallel codes like foreach, then you need to convert your code to a for loop to be able to troubleshoot it.</p>","<p>If this helps anybody, I encountered this while using purr::map() with a function I wrote which was something like this:</p>
<pre><code>find_nearby_shops &lt;- function(base_account) {
   states_table %&gt;% 
        filter(state == base_account$state) %&gt;% 
        left_join(target_locations, by = c(border_states = state)) %&gt;% 
        mutate(x_latitude = base_account$latitude,
               x_longitude = base_account$longitude) %&gt;% 
        mutate(dist_miles = geosphere::distHaversine(p1 = cbind(longitude, latitude), 
                                                     p2 = cbind(x_longitude, x_latitude))/1609.344)
}

nearby_shop_numbers &lt;- base_locations %&gt;% 
    split(f = base_locations$id) %&gt;% 
    purrr::map_df(find_nearby_shops) 
</code></pre>
<p>I would get this error sometimes with samples, but most times I wouldnt.  The root of the problem is that some of the states in the base_locations table (PR) did not exist in the states_table, so essentially I had filtered out everything, and passed an empty table on to mutate.  <strong>The moral of the story is that you may have a data issue and not (just) a code problem (so you may need to clean your data.)</strong></p>
<p>Thanks for agstudy and zx8754s answers above for helping with the debug.</p>",subscript out of bounds in r,How do you fix subscript out of bounds in R?,"Ultimately, the key to fixing this problem is making sure that any value you use to index a matrix, remains inside the bounds of the matrix. The nrow() and ncol() functions are also a good way to check the validity of a value before accessing any part of a matrix.",What does subscript out of bounds mean in R?,"It means you're trying to get something, say a column or row, that doesn't exist. For example, say your table has 10 rows and your function tries to call for row 15.",What does subscript out of range mean in VBA?,"Subscript out of range is an error we encounter in VBA when we try to reference something or a variable which does not exist in a code, for example, let us suppose we do not have a variable named x but we use msgbox function on x we will encounter subscript out of range error.",Why is subscript out of bounds R?,"It means you're trying to get something, say a column or row, that doesn't exist. For example, say your table has 10 rows and your function tries to call for row 15."
https://stackoverflow.com/questions/38906626/curl-to-return-http-status-code-along-with-the-response,shell - Curl to return http status code along with the response,"<p>I was able to get a solution by looking at the curl doc which specifies to use <code>-</code> for the output to get the output to stdout.</p>
<pre><code>curl -o - http://localhost
</code></pre>
<p>To get the response with just the http return code, I could just do</p>
<pre><code>curl -o /dev/null -s -w %{http_code}\n http://localhost
</code></pre>","<p>the verbose mode will tell you everything</p>
<pre><code>curl -v http://localhost
</code></pre>","<p>I found this question because I wanted independent access to BOTH the response and the content in order to add some error handling for the user.</p>
<p>Curl allows you to customize output. <strong>You can print the HTTP status code to std out and write the contents to another file</strong>.</p>
<pre><code>curl -s -o response.txt -w %{http_code} http://example.com
</code></pre>
<p><strong>This allows you to check the return code and then decide if the response is worth printing</strong>, processing, logging, etc.</p>
<pre><code>http_response=$(curl -s -o response.txt -w %{http_code} http://example.com)
if [ $http_response != 200 ]; then
    # handle error
else
    echo Server returned:
    cat response.txt    
fi
</code></pre>
<p>The <code>%{http_code}</code> is a variable substituted by curl. You can do a lot more, or send code to stderr, etc.  See curl manual and the <code>--write-out</code> option.</p>
<blockquote>
<p>-w, --write-out </p>
<p>Make curl display information on stdout after a completed
transfer. The format is a string that may contain plain
text mixed with any number of variables. The format can be
specified as a literal string, or you can have curl read
the format from a file with @filename and to tell curl
to read the format from stdin you write @-.</p>
<p>The variables present in the output format will be
substituted by the value or text that curl thinks fit, as
described below. All variables are specified as
%{variable_name} and to output a normal % you just write
them as %%. You can output a newline by using \n, a
carriage return with \r and a tab space with \t.</p>
<p>The output will be written to standard output, but this
can be switched to standard error by using %{stderr}.</p>
</blockquote>
<p><a href=https://man7.org/linux/man-pages/man1/curl.1.html rel=noreferrer>https://man7.org/linux/man-pages/man1/curl.1.html</a></p>",curl get status code,What is curl response?,"cURL, which stands for client URL, is a command line tool that developers use to transfer data to and from a server. At the most fundamental, cURL lets you talk to a server by specifying the location (in the form of a URL) and the data you want to send.",How do I find my status code?,"Recrawl URLs.
Open URLs in external services (for example, Serpstat, Ahrefs, Google PageSpeed)
Try other reports.",How do I know if my curl command is successful?,"In this way you could just do: args=""-X POST -d@myfile.txt server-URL"" curl -f $args && echo ""SUCCESS!"" || echo ""OH NO!"" The simplest way is to store the response and compare it: $ response=$(curl -X POST -d@myfile.txt server-URL); $ if [ ""Upload successful"" == ""${response}"" ]; then …",How do I check my curl response time?,"Step 1: Create a file name curl-format.txt and copy the following template on to the file.
Step 2: Use the following format to make the curl request.
time_total is the total response time."
https://stackoverflow.com/questions/21710756/recursion-vs-iteration-fibonacci-sequence,java - Recursion vs. Iteration (Fibonacci sequence),"<p>For terseness, Let F(x) be the recursive Fibonacci </p>
<pre><code>F(10) = F(9)                      + F(8)
F(10) = F(8)        + F(7)        + F(7) + F(6)
F(10) = F(7) + F(6) + F(6) + F(5) + 4 more calls.
....
</code></pre>
<p>So your are calling F(8) twice,
F(7) 3 times, F(6) 5 times, F(5) 7 times.. and so on</p>
<p>So with larger inputs, the tree gets bigger and bigger.</p>","<p><a href=http://www.codeproject.com/Articles/21194/Iterative-vs-Recursive-Approaches>This article</a> does a comparison between recursion and iteration and covers their application on generating fibonacci numbers.</p>
<p>As noted in the article,</p>
<blockquote>
<p>The reason for the poor performance is heavy push-pop of the registers in the ill level of each recursive call. </p>
</blockquote>
<p>which basically says there is more overhead in the recursive method.</p>
<p>Also, take a look at <a href=http://en.wikipedia.org/wiki/Memoization>Memoization</a></p>","<p>When doing the recursive implementation of Fibonacci algorithm, you are adding redundant calls by recomputing the same values over and over again.</p>
<pre><code>fib(5) = fib(4) + fib(3)
fib(4) = fib(3) + fib(2)
fib(3) = fib(2) + fib(1)
</code></pre>
<p>Notice, that <code>fib(2)</code> will be redundantly calculated both for <code>fib(4)</code> and for <code>fib(3)</code>.
However this can be overcome by a technique called <a href=https://en.wikipedia.org/wiki/Memoization rel=nofollow noreferrer>Memoization</a>, that improves the efficiency of recursive Fibonacci by storing the values, you have calculated once. Further calls of <code>fib(x)</code> for known values may be replaced by a simple lookup, eliminating the need for further recursive calls.</p>
<p>This is the main difference between the iterative and recursive approaches, if you are interested, there are also other, more <a href=https://www.nayuki.io/page/fast-fibonacci-algorithms rel=nofollow noreferrer>efficient algorithms</a> of calculating Fibonacci numbers.</p>",iterative fibonacci,What is iterative Fibonacci?,"Fibonacci Sequence is a sequence of numbers where the value of the current number is the value of the previous 2 numbers added together. ... An example would be: 0, 1, 1, 2, 3, 5, 8, 13, 21...",Is recursive faster than iterative Fibonacci?,It's NOT. Recursion is an extraordinarily inefficient way to calculate Fibonacci numbers.,What is the time complexity of iterative Fibonacci?,"Therefore, our iterative algorithm has a time complexity of O(n) + O(1) + O(1) = O(n).",What is Fibonacci series algorithm?,"Fibonacci series is a special kind of series in which the next term is equal to the sum of the previous two terms. Thus, the initial two numbers of the series are always given to us. Then, the series will be: ... F10 = 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55."
https://stackoverflow.com/questions/321068/returning-multiple-values-from-a-c-function,Returning multiple values from a C++ function,"<p>For returning two values I use a <code>std::pair</code> (usually typedefd).  You should look at <code>boost::tuple</code> (in C++11 and newer, theres <code>std::tuple</code>) for more than two return results.</p>
<p>With introduction of structured binding in C++ 17, returning <code>std::tuple</code> should probably become accepted standard.</p>","<p>In C++11 you can:</p>
<pre><code>#include &lt;tuple&gt;

std::tuple&lt;int, int&gt; divide(int dividend, int divisor) {
    return  std::make_tuple(dividend / divisor, dividend % divisor);
}

#include &lt;iostream&gt;

int main() {
    using namespace std;

    int quotient, remainder;

    tie(quotient, remainder) = divide(14, 3);

    cout &lt;&lt; quotient &lt;&lt; , &lt;&lt; remainder &lt;&lt; endl;
}
</code></pre>
<p>In C++17:</p>
<pre><code>#include &lt;tuple&gt;

std::tuple&lt;int, int&gt; divide(int dividend, int divisor) {
    return  {dividend / divisor, dividend % divisor};
}

#include &lt;iostream&gt;

int main() {
    using namespace std;

    auto [quotient, remainder] = divide(14, 3);

    cout &lt;&lt; quotient &lt;&lt; , &lt;&lt; remainder &lt;&lt; endl;
}
</code></pre>
<p>or with structs:</p>
<pre><code>auto divide(int dividend, int divisor) {
    struct result {int quotient; int remainder;};
    return result {dividend / divisor, dividend % divisor};
}

#include &lt;iostream&gt;

int main() {
    using namespace std;

    auto result = divide(14, 3);

    cout &lt;&lt; result.quotient &lt;&lt; , &lt;&lt; result.remainder &lt;&lt; endl;

    // or

    auto [quotient, remainder] = divide(14, 3);

    cout &lt;&lt; quotient &lt;&lt; , &lt;&lt; remainder &lt;&lt; endl;
}
</code></pre>","<p>Personally, I generally dislike return parameters for a number of reasons:</p>
<ul>
<li>it is not always obvious in the invocation which parameters are ins and which are outs</li>
<li>you generally have to create a local variable to catch the result, while return values can be used inline (which may or may not be a good idea, but at least you have the option)</li>
<li>it seems cleaner to me to have an in door and an out door to a function -- all the inputs go in here, all the outputs come out there</li>
<li>I like to keep my argument lists as short as possible</li>
</ul>
<p>I also have some reservations about the pair/tuple technique.  Mainly, there is often no natural order to the return values.  How is the reader of the code to know whether <code>result.first</code> is the quotient or the remainder?  And the implementer could change the order, which would break existing code.  This is especially insidious if the values are the same type so that no compiler error or warning would be generated.  Actually, these arguments apply to return parameters as well.</p>
<p>Heres another code example, this one a bit less trivial:</p>
<pre><code>pair&lt;double,double&gt; calculateResultingVelocity(double windSpeed, double windAzimuth,
                                               double planeAirspeed, double planeCourse);

pair&lt;double,double&gt; result = calculateResultingVelocity(25, 320, 280, 90);
cout &lt;&lt; result.first &lt;&lt; endl;
cout &lt;&lt; result.second &lt;&lt; endl;
</code></pre>
<p>Does this print groundspeed and course, or course and groundspeed?  Its not obvious.</p>
<p>Compare to this:</p>
<pre><code>struct Velocity {
    double speed;
    double azimuth;
};
Velocity calculateResultingVelocity(double windSpeed, double windAzimuth,
                                    double planeAirspeed, double planeCourse);

Velocity result = calculateResultingVelocity(25, 320, 280, 90);
cout &lt;&lt; result.speed &lt;&lt; endl;
cout &lt;&lt; result.azimuth &lt;&lt; endl;
</code></pre>
<p>I think this is clearer.</p>
<p>So I think my first choice, in general, is the struct technique.  The pair/tuple idea is likely a great solution in certain cases.  Id like to avoid the return parameters when possible.</p>",c++ function return multiple values,c++ function return multiple values,"While C++ does not have an official way to return multiple values from a function, one can make use of the std::pair , std::tuple , or a local struct to return multiple values.",Can a function return multiple values How?,"If we want the function to return multiple values of same data types, we could return the pointer to array of that data types. We can also make the function return multiple values by using the arguments of the function.",Can C# function return multiple values?,"No, you can't return multiple values from a function in C# (for versions lower than C# 7), at least not in the way you can do it in Python. However, there are a couple alternatives: You can return an array of type object with the multiple values you want in it. You can use out parameters.",Can a function return multiple values in Python How?,"In Python, you can return multiple values by simply return them separated by commas. As an example, define a function that returns a string and a number as follows: Just write each value after the return , separated by commas."
https://stackoverflow.com/questions/20066850/verilog-how-to-instantiate-a-module,Verilog: How to instantiate a module,"<p>This is all generally covered by Section 23.3.2 of <a href=http://standards.ieee.org/findstds/standard/1800-2012.html rel=noreferrer>SystemVerilog IEEE Std 1800-2012</a>.</p>
<p>The simplest way is to instantiate in the main section of top, creating a named instance and wiring the ports up in order:</p>
<pre><code>module top(
   input        clk,
   input        rst_n,
   input        enable,
   input  [9:0] data_rx_1,
   input  [9:0] data_rx_2,
   output [9:0] data_tx_2
);

subcomponent subcomponent_instance_name (
  clk, rst_n, data_rx_1, data_tx ); 

endmodule
</code></pre>
<p>This is described in Section 23.3.2.1 of <a href=http://standards.ieee.org/findstds/standard/1800-2012.html rel=noreferrer>SystemVerilog IEEE Std 1800-2012</a>.</p>
<p>This has a few draw backs especially regarding the port order of the subcomponent code. simple refactoring here can break connectivity or change behaviour. for example if some one else fixs a bug and reorders the ports for some reason, switching the clk and reset order. There will be no connectivity issue from your compiler but will not work as intended.</p>
<pre><code>module subcomponent(
  input        rst_n,       
  input        clk,
  ...
</code></pre>
<p>It is therefore recommended to connect using named ports, this also helps tracing connectivity of wires in the code.</p>
<pre><code>module top(
   input        clk,
   input        rst_n,
   input        enable,
   input  [9:0] data_rx_1,
   input  [9:0] data_rx_2,
   output [9:0] data_tx_2
);

subcomponent subcomponent_instance_name (
  .clk(clk), .rst_n(rst_n), .data_rx(data_rx_1), .data_tx(data_tx) ); 

endmodule
</code></pre>
<p>This is described in Section 23.3.2.2 of <a href=http://standards.ieee.org/findstds/standard/1800-2012.html rel=noreferrer>SystemVerilog IEEE Std 1800-2012</a>.</p>
<p>Giving each port its own line and indenting correctly adds to the readability and code quality. </p>
<pre><code>subcomponent subcomponent_instance_name (
  .clk      ( clk       ), // input
  .rst_n    ( rst_n     ), // input
  .data_rx  ( data_rx_1 ), // input  [9:0]
  .data_tx  ( data_tx   )  // output [9:0]
);
</code></pre>
<p>So far all the connections that have been made have reused inputs and output to the sub module and no connectivity wires have been created. What happens if we are to take outputs from one component to another:</p>
<pre><code>clk_gen( 
  .clk      ( clk_sub   ), // output
  .en       ( enable    )  // input

subcomponent subcomponent_instance_name (
  .clk      ( clk_sub   ), // input
  .rst_n    ( rst_n     ), // input 
  .data_rx  ( data_rx_1 ), // input  [9:0]
  .data_tx  ( data_tx   )  // output [9:0]
);
</code></pre>
<p>This nominally works as a wire for clk_sub is automatically created, there is a danger to relying on this. it will only ever create a 1 bit wire by default. An example where this is a problem would be for the data:</p>
<p><strong>Note that the instance name for the second component has been changed</strong></p>
<pre><code>subcomponent subcomponent_instance_name (
  .clk      ( clk_sub   ), // input
  .rst_n    ( rst_n     ), // input 
  .data_rx  ( data_rx_1 ), // input  [9:0]
  .data_tx  ( data_temp )  // output [9:0]
);
subcomponent subcomponent_instance_name2 (
  .clk      ( clk_sub   ), // input
  .rst_n    ( rst_n     ), // input 
  .data_rx  ( data_temp ), // input  [9:0]
  .data_tx  ( data_tx   )  // output [9:0]
);
</code></pre>
<p>The issue with the above code is that data_temp is only 1 bit wide, there would be a compile warning about port width mismatch. The connectivity wire needs to be created and a width specified. I would recommend that all connectivity wires be explicitly written out.</p>
<pre><code>wire [9:0] data_temp
subcomponent subcomponent_instance_name (
  .clk      ( clk_sub   ), // input
  .rst_n    ( rst_n     ), // input 
  .data_rx  ( data_rx_1 ), // input  [9:0]
  .data_tx  ( data_temp )  // output [9:0]
);
subcomponent subcomponent_instance_name2 (
  .clk      ( clk_sub   ), // input
  .rst_n    ( rst_n     ), // input 
  .data_rx  ( data_temp ), // input  [9:0]
  .data_tx  ( data_tx   )  // output [9:0]
);
</code></pre>
<p>Moving to SystemVerilog there are a few tricks available that save typing a handful of characters. I believe that they hinder the code readability and can make it harder to find bugs.</p>
<p>Use <code>.port</code> with no brackets to connect to a wire/reg of the same name. This can look neat especially with lots of clk and resets but at some levels you may generate different clocks or resets or you actually do not want to connect to the signal of the same name but a modified one and this can lead to wiring bugs that are not obvious to the eye. </p>
<pre><code>module top(
   input        clk,
   input        rst_n,
   input        enable,
   input  [9:0] data_rx_1,
   input  [9:0] data_rx_2,
   output [9:0] data_tx_2
);

subcomponent subcomponent_instance_name (
  .clk,                    // input **Auto connect**
  .rst_n,                  // input **Auto connect**
  .data_rx  ( data_rx_1 ), // input  [9:0]
  .data_tx  ( data_tx   )  // output [9:0]
);

endmodule
</code></pre>
<p>This is described in Section 23.3.2.3 of <a href=http://standards.ieee.org/findstds/standard/1800-2012.html rel=noreferrer>SystemVerilog IEEE Std 1800-2012</a>.</p>
<p>Another trick that I think is even worse than the one above is <code>.*</code> which connects unmentioned ports to signals of the same wire. I consider this to be quite dangerous in production code. It is not obvious when new ports have been added and are missing or that they might accidentally get connected if the new port name had a counter part in the instancing level, they get auto connected and no warning would be generated.</p>
<pre><code>subcomponent subcomponent_instance_name (
  .*,                      // **Auto connect**
  .data_rx  ( data_rx_1 ), // input  [9:0]
  .data_tx  ( data_tx   )  // output [9:0]
);
</code></pre>
<p>This is described in Section 23.3.2.4 of <a href=http://standards.ieee.org/findstds/standard/1800-2012.html rel=noreferrer>SystemVerilog IEEE Std 1800-2012</a>.</p>","<p>Be sure to check out verilog-mode and especially verilog-auto. <a href=http://www.veripool.org/wiki/verilog-mode/ rel=nofollow>http://www.veripool.org/wiki/verilog-mode/</a> It is a verilog mode for emacs, but plugins exist for vi(m?) for example.</p>
<p>An instantiation can be automated with AUTOINST. The comment is expanded with <code>M-x verilog-auto</code> and can afterwards be manually edited.</p>
<pre><code>subcomponent subcomponent_instance_name(/*AUTOINST*/);
</code></pre>
<p>Expanded</p>
<pre><code>subcomponent subcomponent_instance_name (/*AUTOINST*/
  //Inputs
  .clk,         (clk)           
  .rst_n,       (rst_n)
  .data_rx      (data_rx_1[9:0]),
  //Outputs
  .data_tx      (data_tx[9:0])
);
</code></pre>
<p>Implicit wires can be automated with <code>/*AUTOWIRE*/</code>. Check the link for further information.</p>","<p>One thing not mentioned in the answers (and actually not asked in the question either) is how to instantiate a module with a <em>parameter</em>. I always have hard time to remember the order and the syntax so here goes:</p>
<p><code>&lt;component_name&gt; #(.parameter_name( parameter_value ), ... ) &lt;instance_name&gt;(.port_name( wire/reg_name ), ...)</code></p>
<p>So if you have a module fooBar with a parameter <strong>N</strong> and you want to create a fooBarInstance having a different parameter value instead:</p>
<pre><code>module fooBar #(parameter N = 8) (input [N-1:0] foo, output[N-1:0] bar)
endmodule

// Instantiate fooBar with N=12
fooBar #(.N(12)) fooBarInstance(.foo(fooWire), .bar(barReg));
</code></pre>",verilog module instantiation,verilog module instantiation,"A module provides a template from which you can create actual objects. When a module is invoked, Verilog creates a unique object from the template. Each object has its own name, variables, parameters, and I/O interface.",What is the difference between module and instance in Verilog?,"The MUX_module contains references to each of the lower level modules and describes the interconnections between them. In Verilog jargon, a reference to a lower level module is called a module instance. Each instance is an independent, concurrently active copy of a module. Module Instances The MUX_module contains references to each of the lower level modules and describes the interconnections between them. In Verilog jargon, a reference to a lower level module is called a module instance. Each instance is an independent, concurrently active copy of a module.",How do I instantiate a module in another module in Verilog?,"A module can be instantiated in another module thus creating hierarchy. Module instantiation consists of module_name followed by instance_name and port_association_list. Need of instance_name is, we can have multiple instance of same module in the same program.",Can you have multiple modules in Verilog?,"All variable declarations, dataflow statements, functions or tasks and lower module instances if any, must be defined within the module and endmodule keywords. There can be multiple modules with different names in the same file and can be defined in any order."
https://stackoverflow.com/questions/8220702/error-int-object-is-not-subscriptable-python,Error: int object is not subscriptable - Python,"<p>When you type <code>x = 0</code> that is creating a new <code>int</code> variable (name) and assigning a zero to it.</p>
<p>When you type <code>x[age1]</code> that is trying to access the <code>age1</code>th entry, as if <code>x</code> were an array.</p>","<p>The problem is in the line,</p>
<pre><code>int([x[age1]])
</code></pre>
<p>What you want is</p>
<pre><code>x = int(age1)
</code></pre>
<p>You also need to convert the int to a string for the output...</p>
<pre><code>print Hi,  + name1+  you will be 21 in:  + str(twentyone) +  years.
</code></pre>
<p>The complete script looks like,</p>
<pre><code>name1 = raw_input(Whats your name? )
age1 = raw_input (how old are you? )
x = 0
x = int(age1)
twentyone = 21 - x
print Hi,  + name1+  you will be 21 in:  + str(twentyone) +  years.
</code></pre>","<p>When you write <code>x = 0</code>, <code>x</code> is an int...so you cant do <code>x[age1]</code> because <code>x</code> is <code>int</code></p>",int' object is not subscriptable,int' object is not subscriptable,"Integers are not subscriptable objects. Only objects that contain other objects, like strings, lists, tuples, and dictionaries, are subscriptable. ... Lists are subscriptable which means you can use indexing to retrieve a value from a list.",Are tuples Subscriptable?,"Only objects that contain other objects, like strings, lists, tuples, and dictionaries, are subscriptable.",What is Subscriptable?,"In simple words, objects which can be subscripted are called sub scriptable objects. In Python, strings, lists, tuples, and dictionaries fall in subscriptable category.",What does TypeError function object is not Subscriptable mean in Python?,"The “TypeError: 'function' object is not subscriptable” error is raised when you try to access an item from a function as if the function were an iterable object, like a string or a list."
https://stackoverflow.com/questions/49100556/what-is-the-use-of-train-on-batch-in-keras,machine learning - What is the use of train_on_batch() in keras?,"<p>For this question, its a <a href=https://github.com/keras-team/keras/issues/2708#issuecomment-218803413 rel=noreferrer>simple answer from the primary author</a>:</p>
<blockquote>
<p>With <code>fit_generator</code>, you can use a generator for the validation data as
  well. In general, I would recommend using <code>fit_generator</code>, but using
  <code>train_on_batch</code> works fine too. These methods only exist for the sake of
  convenience in different use cases, there is no correct method.</p>
</blockquote>
<p><code>train_on_batch</code> allows you to expressly update weights based on a collection of samples you provide, without regard to any fixed batch size. You would use this in cases when that is what you want: to train on an explicit collection of samples. You could use that approach to maintain your own iteration over multiple batches of a traditional training set but allowing <code>fit</code> or <code>fit_generator</code> to iterate batches for you is likely simpler.</p>
<p>One case when it might be nice to use <code>train_on_batch</code> is for updating a pre-trained model on a single new batch of samples. Suppose youve already trained and deployed a model, and sometime later youve received a new set of training samples previously never used. You could use <code>train_on_batch</code> to directly update the existing model only on those samples. Other methods can do this too, but it is rather explicit to use <code>train_on_batch</code> for this case.</p>
<p>Apart from special cases like this (either where you have some pedagogical reason to maintain your own cursor across different training batches, or else for some type of semi-online training update on a special batch), it is probably better to just always use <code>fit</code> (for data that fits in memory) or <code>fit_generator</code> (for streaming batches of data as a generator).</p>","<p><code>train_on_batch()</code> gives you greater control of the state of the LSTM, for example, when using a stateful LSTM and controlling calls to <code>model.reset_states()</code> is needed. You may have multi-series data and need to reset the state after each series, which you can do with <code>train_on_batch()</code>, but if you used <code>.fit()</code> then the network would be trained on all the series of data without resetting the state.  Theres no right or wrong, it depends on what data youre using, and how you want the network to behave.</p>","<p>Train_on_batch will also see a performance increase over fit and fit generator if youre using large datasets and dont have easily serializable data (like high rank numpy arrays), to write to tfrecords.</p>
<p>In this case you can save the arrays as numpy files and load up smaller subsets of them (traina.npy, trainb.npy etc) in memory, when the whole set wont fit in memory. You can then use tf.data.Dataset.from_tensor_slices and then using train_on_batch with your subdataset, then loading up another dataset and calling train on batch again, etc, now youve trained on your entire set and can control exactly how much and what of your dataset trains your model. You can then define your own epochs, batch sizes, etc with simple loops and functions to grab from your dataset.</p>",keras train_on_batch,What is Train_on_batch?,"train_on_batch allows you to expressly update weights based on a collection of samples you provide, without regard to any fixed batch size. You would use this in cases when that is what you want: to train on an explicit collection of samples.",What does model Train_on_batch return?,"edited. train_on_batch computes a forward pass through the model gives you the outputs ( loss , etc...), and then does a backward pass ( backprop ) to update the weight of the model. The logical flow of the code you have above: Forward pass (compute value of c1) Backward pass (update model weights)",What is model compile in keras?,"Keras is an open-source Python library. It contains a ton of built-in functions and methods that are very useful for the developer. The model compiles this input data, evaluate it, and predict the output. ...",What is train on batch keras?,"train_on_batch allows you to expressly update weights based on a collection of samples you provide, without regard to any fixed batch size. You would use this in cases when that is what you want: to train on an explicit collection of samples."
https://stackoverflow.com/questions/37586407/rotate-gameobject-over-time,c# - Rotate GameObject over time,"<p>Most examples out there including Unity examples from their official website are using Lerp in the wrong way. They didnt even bother to describe how it works in the API documentation. They just starch it in the <code>Update()</code> function and call it a day.</p>
<p><code>Mathf.Lerp</code>, <code>Vector3.Lerp</code>, and <code>Quaternion.Slerp</code> work by changing from one position/rotation to another with the <strong>t</strong> value(last parameter) being passed in.That <strong>t</strong> value is also know as time.</p>
<p>The min of the <strong>t</strong> value is <strong>0f</strong> and the max is <strong>1f</strong>.</p>
<p>I will explain this with <code>Mathf.Lerp</code> to make it easier to understand. The <code>Lerp</code> functions are all the-same for both <code>Mathf.Lerp</code>, <code>Vector</code> and <code>Quaternion</code>.</p>
<p>Remember that <code>Lerp</code> takes two values and returns values between them. If we have a value of <strong>1</strong> and <strong>10</strong> and we do Lerp on them: </p>
<pre><code> float x = Mathf.Lerp(1f, 10f, 0f); will return 1.
 float x = Mathf.Lerp(1f, 10f, 0.5f); will return 5.5
 float x = Mathf.Lerp(1f, 10f, 1f);  will return 10
</code></pre>
<p>As you can see, the <code>t(0)</code> returns the <strong>min</strong> of the number passed in, <code>t(1)</code> returns the <strong>max</strong> value passed in and <code>t(0.5)</code> will return <strong>mid</strong> point between the <strong>min</strong> and the <strong>max</strong> value. You are doing it wrong when you pass any <strong>t</strong> value that is <code>&lt; 0</code> or <code>&gt; 1</code>. That code in you <code>Update()</code> function is doing just that. <code>Time.time</code> will increase every second and will be <code>&gt; 1</code> in a second, so you have problems with that.</p>
<p>It recommended to use <code>Lerp</code> in another function/Coroutine instead of the Updated function.</p>
<p><strong>Note</strong>: </p>
<p>Using <code>Lerp</code> has a bad side of it when it comes to rotation. <code>Lerp</code> does not know how to rotate Object with the shortest path. So bear that in mind. For example, you have an Object with <code>0,0,90</code> position. Lets say you want to move the rotation from that to <code>0,0,120</code> <code>Lerp</code> can sometimes rotate left instead of right to reach that new position which means it take longer to reach that distance.</p>
<p>Lets say we want to make the rotation <code>(0,0,90)</code> from whatever the current rotation is. The code below will change the rotation to <code>0,0,90</code> in 3 seconds. </p>
<p><strong>ROTATION OVER TIME</strong>:</p>
<pre><code>void Start()
{
    Quaternion rotation2 = Quaternion.Euler(new Vector3(0, 0, 90));
    StartCoroutine(rotateObject(objectToRotate, rotation2, 3f));
}

bool rotating = false;
public GameObject objectToRotate;
IEnumerator rotateObject(GameObject gameObjectToMove, Quaternion newRot, float duration)
{
    if (rotating)
    {
        yield break;
    }
    rotating = true;

    Quaternion currentRot = gameObjectToMove.transform.rotation;

    float counter = 0;
    while (counter &lt; duration)
    {
        counter += Time.deltaTime;
        gameObjectToMove.transform.rotation = Quaternion.Lerp(currentRot, newRot, counter / duration);
        yield return null;
    }
    rotating = false;
}
</code></pre>
<p><strong>INCREMENTAL ANGULAR ROTATION OVER TIME:</strong></p>
<p>And to just rotate the Object to 90 in z axis, the code below is a great example of that. Please understand there is a difference between moving Object to new rotational point and just rotating it. </p>
<pre><code>void Start()
{
    StartCoroutine(rotateObject(objectToRotate, new Vector3(0, 0, 90), 3f));
}

bool rotating = false;
public GameObject objectToRotate;

IEnumerator rotateObject(GameObject gameObjectToMove, Vector3 eulerAngles, float duration)
{
    if (rotating)
    {
        yield break;
    }
    rotating = true;

    Vector3 newRot = gameObjectToMove.transform.eulerAngles + eulerAngles;

    Vector3 currentRot = gameObjectToMove.transform.eulerAngles;

    float counter = 0;
    while (counter &lt; duration)
    {
        counter += Time.deltaTime;
        gameObjectToMove.transform.eulerAngles = Vector3.Lerp(currentRot, newRot, counter / duration);
        yield return null;
    }
    rotating = false;
}
</code></pre>
<p>All my examples are based on frame-rate of the device. You can use real-time by replacing <code>Time.deltaTime</code> with <code>Time.delta</code> but more calculation is required.</p>","<p>Before anything, you cant add 180 on euler angles like that, and thats mainly what is causing your problem. Youd better use quaternion directly instead, or work on the transform itself.</p>
<p>You can think of a quaternion as an orientation in space. In contrary to what have been said, I do recommend learning how to use them if you can. However, I dont recommend using euler angles at all... as theyre suject to different writing conventions, and will fail sometimes. You can look at gimbal lock if you want details about that.</p>
<p>Simply a slerp or lerp (standing for spherical linear interpolation, or linear interpolation respectively) is a way to interpolate (go from one orientation to another, by increasing t from 0 to 1, in a coroutine or anywhere else) between orientation A and B. The difference between the two is that the slerp is giving you the shortest path from A to B. </p>
<p>In the end, when t = 1, lerp(A,B,t) and slerp(A,B,t) will give you B.</p>
<p>In your case, if you want to instantly rotate an object in space to a specific orientation, I suggest you use Quaternion.AngleAxis which is the most forward way to describe mathematically a quaternion.</p>
<p>If you want to add a rotation, say 90° to you actual orientation (without animation between the two), you can do something like this : </p>
<p>transform.rotation *= Quaternion.AngleAxis(axis_of_rotation, angle)
or use transform.rotate (depending on the parameters, it can be a right multiply, or left : local, or world transform).</p>
<p>Programmers answer is detailling how to animate your transform. But I do suggest you to investigate quaternion themselves, as it will give you global understanding of space transforms.</p>",,unity rotate over time,How do you rotate to in unity?,"4 Answers. If you want to rotate the object to a specific angle use: float degrees = 90; Vector3 to = new Vector3(degrees, 0, 0); transform.",How do I rotate an object in Unity continuously?,"Just like the Rotate function, Rotate Around is only applied once when it's called, which means if you want to create continuous rotation, you'll need to call Rotate Around in Update, multiplying the angle value by Delta Time.",How do you rotate an object in Unity 3d?,"If you want to rotate the object to a specific angle use: float degrees = 90; Vector3 to = new Vector3(degrees, 0, 0); transform.",How do you rotate an object in unity?,"If you want to rotate the object to a specific angle use: float degrees = 90; Vector3 to = new Vector3(degrees, 0, 0); transform."
https://stackoverflow.com/questions/19646719/eclipse-command-line-arguments,java - Eclipse command line arguments,"<ol>
<li>Click on <strong>Run</strong> -&gt; <strong>Run Configurations</strong> </li>
<li>Click on <strong>Arguments</strong> tab  </li>
<li>In <strong>Program Arguments</strong> section , Enter your arguments.  </li>
<li>Click <strong>Apply</strong> </li>
</ol>
<p><em>It is sure to work cause I tried it in mine right before I wrote this answer</em></p>","<p>There is a situation (bug) where modifying the Run -&gt; Run Configurations arguments does not work, since the actual run configuration being executed is actually hidden from you.</p>
<p>So updating the visible one will not be reflected in your actual run.</p>
<p>Example:</p>
<pre><code>import static org.junit.Assert.assertEquals;

import org.junit.Test;

public class EclipseRunConfigurationTest {

    @Test
    public void test() {
        assertEquals(foo, System.getProperty(runProperty));
    }

}
</code></pre>
<ol>
<li>Run it - it will fail.</li>
<li>Modify the run configuration using the method specified by Little Child.  add -DrunProperty=foo VM parameter</li>
<li>Run it again - it will pass</li>
<li>Debug it, then switch to the debug view, 
<ul>
<li>RClick the  Junit launch -&gt; Edit Rerun EclipseRunConfigurationTest...</li>
<li>Change the VM parameter to -DrunProperty=bar</li>
<li>Apply and Debug - it will fail</li>
</ul></li>
<li>Open the Run/Debug manager again 
<ul>
<li>Note that Rerun EclipseRunConfigurationTest is not listed.  </li>
<li>Note that the VM parameter is still -DrunProperty=foo</li>
<li>No amount of changing it makes the slightest bit of difference.</li>
</ul></li>
</ol>
<p>I shall file a bug report.</p>
<p>The above was run on Eclipse Kepler running on Fedora 20.</p>","<p>A small update in the solution given by Little Child above, to make it work with arguments having spaces in them.
e.g. first argument - abc def
     second argument - ghi
     third argument - jkl mno pqrs</p>
<p>In Program Arguments, give them like this using double quotes</p>
<pre><code>abc def
ghi
jkl mno pqrs
</code></pre>
<p>If you dont give spaces it will take abc as first argument and def as second argument and ghi as thrid argument and so on..</p>",eclipse command line arguments,eclipse command line arguments,"To specify command line arguments in eclipse, go to Run -> Run… Make sure you are running the correct project for which you want to specify command line arguments for, and then select the arguments tab. Now enter the arguments you want, separated by spaces.",How do I get the command line in Eclipse?,"To get the full command line, you can open the Debug view from Window>Show View>Other... . Right click on the last launch and go to properties. Eclipse will list the exact command line.",Where do I put VM arguments in Eclipse?,"Step 1: Open the IDE and right-click on the application in which you want to pass VM arguments.
Step 2: Click on the Run As » Run Configurations…
Step 3: Click on the Arguments tab and in the VM arguments: box, type the arguments that you want to pass.",How do I run an argument from the command line?,"option. You can test command line arguments by running an executable from the ""Command Prompt"" in Windows or from the ""DOS prompt"" in older versions of Windows. You can also use command line arguments in program shortcuts, or when running an application by using Start -> Run."
